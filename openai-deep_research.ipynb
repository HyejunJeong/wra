{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c27944-1303-4b1e-9f46-a54216c12eb5",
   "metadata": {},
   "source": [
    "# OpenAI Deep-Research api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014abe41-5062-47e1-968e-daf61b8ea797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import datetime\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_key_here\"\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"your_gemini_key_here\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your_google_key_here\"\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"your_deepseek_key_here\"\n",
    "\n",
    "\n",
    "client = OpenAI(timeout=3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a8934-cedd-4e7f-8529-fb53f50d456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Run Deep Research over prompts and save deep_topic_{i}.json\n",
    "\n",
    "import os, re, json, time, pathlib\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- config ---\n",
    "INPUT_PATH = \"data/prompts/SESSION14-DR.txt\"      \n",
    "OUT_DIR    = \"prompt_reconstruction/deep_research\"           \n",
    "MODEL      = \"o3-deep-research\"\n",
    "MAX_PROMPTS = 10  # set an int (e.g., 10) to limit, or None for all\n",
    "\n",
    "# system instructions (as in your snippet)\n",
    "system_message = \"\"\"\n",
    "You are a professional researcher preparing a structured, data-driven report on behalf of a global health economics team. Your task is to analyze the health question the user poses.\n",
    "\n",
    "Do:\n",
    "- Focus on data-rich insights: include specific figures, trends, statistics, and measurable outcomes (e.g., reduction in hospitalization costs, market size, pricing trends, payer adoption).\n",
    "- When appropriate, summarize data in a way that could be turned into charts or tables, and call this out in the response (e.g., “this would work well as a bar chart comparing per-patient costs across regions”).\n",
    "- Prioritize reliable, up-to-date sources: peer-reviewed research, health organizations (e.g., WHO, CDC), regulatory agencies, or pharmaceutical earnings reports.\n",
    "- Include inline citations and return all source metadata.\n",
    "\n",
    "Be analytical, avoid generalities, and ensure that each section supports data-backed reasoning that could inform healthcare policy or financial modeling.\n",
    "\"\"\"\n",
    "\n",
    "TOOLS = [\n",
    "    {\"type\": \"web_search_preview\"},\n",
    "    {\"type\": \"code_interpreter\", \"container\": {\"type\": \"auto\", \"file_ids\": []}},\n",
    "]\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def read_prompts_from_file(path: str):\n",
    "    \"\"\"\n",
    "    Parse blocks labeled 'Prompt N:' (case-insensitive) and return\n",
    "    a list of (idx:int, text:str), sorted by idx.\n",
    "    \"\"\"\n",
    "    text = pathlib.Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    pat = re.compile(r\"(?:^|\\n)Prompt\\s+(\\d+):\\s*(.*?)(?=\\nPrompt\\s+\\d+:|$)\", re.IGNORECASE | re.DOTALL)\n",
    "    blocks = pat.findall(text)\n",
    "    prompts = [(int(n), body.strip()) for (n, body) in blocks]\n",
    "    prompts.sort(key=lambda x: x[0])\n",
    "    return prompts\n",
    "\n",
    "def call_deep_research(prompt_text: str):\n",
    "    return client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=[\n",
    "            {\"role\": \"developer\", \"content\": [{\"type\": \"input_text\", \"text\": system_message}]},\n",
    "            {\"role\": \"user\",      \"content\": [{\"type\": \"input_text\", \"text\": prompt_text}]},\n",
    "        ],\n",
    "        reasoning={\"summary\": \"auto\"},\n",
    "        tools=TOOLS,\n",
    "    )\n",
    "\n",
    "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "prompts = read_prompts_from_file(INPUT_PATH)\n",
    "if MAX_PROMPTS is not None:\n",
    "    prompts = prompts[:MAX_PROMPTS]\n",
    "\n",
    "print(f\"Running Deep Research on {len(prompts)} prompts...\")\n",
    "for i, (idx, prompt_text) in enumerate(prompts, start=1):\n",
    "    out_path = pathlib.Path(OUT_DIR) / f\"deep_topic_{i}.json\"\n",
    "    print(f\"→ Prompt {idx} → {out_path.name}\")\n",
    "\n",
    "    # simple retry for transient errors\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            resp = call_deep_research(prompt_text)\n",
    "            # save raw JSON; support different SDKs\n",
    "            try:\n",
    "                raw_json = resp.model_dump()\n",
    "            except Exception:\n",
    "                raw_json = json.loads(resp.json())\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(raw_json, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"✅ Saved {out_path}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"  [Attempt {attempt+1}] Error: {e} → retrying in {wait}s\")\n",
    "            time.sleep(wait)\n",
    "    else:\n",
    "        print(f\"❌ Failed after retries for Prompt {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c459cd3-cf68-44c1-b48c-bc35e4df2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "for i in range(1, 11):\n",
    "    input_path = f\"deep_research_outputs/deep_topic_{i}.json\"\n",
    "    output_path = f\"deep_research_outputs/deep_topic_{i}_domains.json\"\n",
    "    domains = set()\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        response_data = json.load(f)\n",
    "\n",
    "    response = response_data.get(\"output\", [])\n",
    "\n",
    "    for step in response:\n",
    "        action = step.get(\"action\", {})\n",
    "        if (\n",
    "            step.get(\"type\") == \"web_search_call\"\n",
    "            and isinstance(action, dict)\n",
    "            and \"url\" in action\n",
    "        ):\n",
    "            url = action[\"url\"]\n",
    "            if isinstance(url, str):\n",
    "                domain = urlparse(url).netloc\n",
    "                if domain:\n",
    "                    domains.add(domain)\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(list(domains), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Saved {len(domains)} unique domains to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd1995-b2cf-4359-a31b-08eddc0bb7c5",
   "metadata": {},
   "source": [
    "# OpenAI Web-Search (through api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143eb651-ee8b-40ff-9fdb-09f4b07de901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_key_here\"\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"your_gemini_key_here\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your_google_key_here\"\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"your_deepseek_key_here\"\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# prompt = \"A friend from Kenya is visiting you and you'd like to surprise him with by cooking a traditional Swahili dish. You want to learn about Swahili dishes and how to cook them. Find web pages about Swahili home cooking.\",\n",
    "prompt = \"Your friend would like to quit smoking. You would like to provide him with relevant information about: different ways to quit smoking, programs available to help quit smoking, benefits of quitting smoking, second effects of quitting smoking, using hypnosis to quit smoking, using the cold turkey method to quit smoking.\\\n",
    "Only use information from pages you actually visit by clicking links—do not rely on search result summaries or prior knowledge.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input=prompt,\n",
    "    stream=True,\n",
    "    tools=[{\"type\": \"web_search\"}]\n",
    ")\n",
    "\n",
    "# Store visited URLs with timestamps\n",
    "visited_urls = []\n",
    "\n",
    "for event in response:\n",
    "    # Check for streamed annotation events\n",
    "    if event.type == \"response.output_text.annotation.added\":\n",
    "        annotation = event.annotation\n",
    "        if annotation and annotation.get(\"type\") == \"url_citation\":\n",
    "            url = annotation.get(\"url\")\n",
    "            domain = urlparse(url).netloc\n",
    "            timestamp = datetime.datetime.utcnow().isoformat()\n",
    "\n",
    "            visited_info = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"url\": url,\n",
    "                \"domain\": domain,\n",
    "                \"title\": annotation.get(\"title\"),\n",
    "                \"sequence_number\": event.sequence_number,\n",
    "                \"item_id\": event.item_id\n",
    "            }\n",
    "\n",
    "            visited_urls.append(visited_info)\n",
    "\n",
    "            # Print each as it's received\n",
    "            print(f\"[{timestamp}] Visited domain: {domain} ({url})\")\n",
    "\n",
    "# print(response)\n",
    "# for annon in response.output[1].content[0].annotations:\n",
    "#     print(annon.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe5977-4eda-43d0-8c1c-66b1917686e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ed658-d013-4183-9621-9b4a0a7f7446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7182c88-a24c-41cd-a2f4-d72876dba6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219ac90-cf0c-472b-ab1c-6e0a95d512e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AutoGen)",
   "language": "python",
   "name": "autogen-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
